{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset I \n",
    "The dimensional discrete Fourier Transform(DDFT) on the raw sensor data to obtain training and test data with 441 \n",
    "features.\n",
    "Reference Source Code: https://www.kaggle.com/ajcostarino/ingv-volcanic-eruption-prediction-lgbm-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing essential libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "import cv2\n",
    "import random \n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.stats as spstats\n",
    "\n",
    "# Basic statistics will calculate distribution values for each sensor\n",
    "def basic_statistics(t_X, x, s, sensor, postfix=''):\n",
    "    \"\"\"Computes basic statistics for the training feature set.\n",
    "    \n",
    "    Args:\n",
    "        t_X (pandas.DataFrame): The feature set being built.\n",
    "        x (pandas.Series): The signal values.\n",
    "        s (int): The integer number of the segment.\n",
    "        postfix (str): The postfix string value.\n",
    "    Return:\n",
    "        t_X (pandas.DataFrame): The feature set being built.\n",
    "    \"\"\"\n",
    "\n",
    "    t_X.loc[s, f'{sensor}_sum{postfix}']       = x.sum()\n",
    "    t_X.loc[s, f'{sensor}_mean{postfix}']      = x.mean()\n",
    "    t_X.loc[s, f'{sensor}_std{postfix}']       = x.std()\n",
    "    t_X.loc[s, f'{sensor}_var{postfix}']       = x.var() \n",
    "    t_X.loc[s, f'{sensor}_max{postfix}']       = x.max()\n",
    "    t_X.loc[s, f'{sensor}_min{postfix}']       = x.min()\n",
    "    t_X.loc[s, f'{sensor}_median{postfix}']    = x.median()\n",
    "    t_X.loc[s, f'{sensor}_skew{postfix}']      = x.skew()\n",
    "    t_X.loc[s, f'{sensor}_mad{postfix}']       = x.mad()\n",
    "    t_X.loc[s, f'{sensor}_kurtosis{postfix}']  = x.kurtosis()\n",
    "\n",
    "    return t_X\n",
    "\n",
    "\n",
    "#Quantiles will calculate quantiles for each sensor\n",
    "def quantiles(t_X, x, s, sensor, postfix=''):\n",
    "    \"\"\"Calculates quantile features for the training feature set.\n",
    "    Args:\n",
    "        t_X (pandas.DataFrame): The feature set being built.\n",
    "        x (pandas.Series): The signal values.\n",
    "        s (int): The integer number of the segment.\n",
    "        postfix (str): The postfix string value.\n",
    "    Return:\n",
    "        t_X (pandas.DataFrame): The feature set being built.\n",
    "    \"\"\"\n",
    "    t_X.loc[s, f'{sensor}_q999{postfix}']     = np.quantile(x ,0.999)\n",
    "    t_X.loc[s, f'{sensor}_q99{postfix}']      = np.quantile(x, 0.99)\n",
    "    t_X.loc[s, f'{sensor}_q95{postfix}']      = np.quantile(x, 0.95)\n",
    "    t_X.loc[s, f'{sensor}_q87{postfix}']      = np.quantile(x, 0.87)\n",
    "    t_X.loc[s, f'{sensor}_q13{postfix}']      = np.quantile(x, 0.13)  \n",
    "    t_X.loc[s, f'{sensor}_q05{postfix}']      = np.quantile(x, 0.05)\n",
    "    t_X.loc[s, f'{sensor}_q01{postfix}']      = np.quantile(x, 0.01)\n",
    "    t_X.loc[s, f'{sensor}_q001{postfix}']     = np.quantile(x ,0.001)\n",
    "    \n",
    "    x_abs = np.abs(x)\n",
    "    t_X.loc[s, f'{sensor}_q999_abs{postfix}'] = np.quantile(x_abs, 0.999)\n",
    "    t_X.loc[s, f'{sensor}_q99_abs{postfix}']  = np.quantile(x_abs, 0.99)\n",
    "    t_X.loc[s, f'{sensor}_q95_abs{postfix}']  = np.quantile(x_abs, 0.95)\n",
    "    t_X.loc[s, f'{sensor}_q87_abs{postfix}']  = np.quantile(x_abs, 0.87)\n",
    "    t_X.loc[s, f'{sensor}_q13_abs{postfix}']  = np.quantile(x_abs, 0.13)\n",
    "    t_X.loc[s, f'{sensor}_q05_abs{postfix}']  = np.quantile(x_abs, 0.05)\n",
    "    t_X.loc[s, f'{sensor}_q01_abs{postfix}']  = np.quantile(x_abs, 0.01)\n",
    "    t_X.loc[s, f'{sensor}_q001_abs{postfix}'] = np.quantile(x_abs, 0.001)\n",
    "    \n",
    "    t_X.loc[s, f'{sensor}_iqr']     = np.subtract(*np.percentile(x, [75, 25]))\n",
    "    t_X.loc[s, f'{sensor}_iqr_abs'] = np.subtract(*np.percentile(x_abs, [75, 25]))\n",
    "\n",
    "    return t_X\n",
    "\n",
    "#Linear regression builds a linear regression model for each sensor and returns the coefficients\n",
    "def __linear_regression(arr, abs_v=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_v:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    fit_X = idx.reshape(-1, 1)\n",
    "    lr.fit(fit_X, arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "\n",
    "def __classic_sta_lta(x, length_sta, length_lta):\n",
    "    sta = np.cumsum(x ** 2)\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "    return sta / lta\n",
    "\n",
    "\n",
    "def linear_regression(t_X, x, s, sensor, postfix=''):\n",
    "    t_X.loc[s, f'{sensor}_lr_coef{postfix}'] = __linear_regression(x)\n",
    "    t_X.loc[s, f'{sensor}_lr_coef_abs{postfix}'] = __linear_regression(x, True)\n",
    "    return t_X\n",
    "\n",
    "\n",
    "def classic_sta_lta(t_X, x, sensor, s):\n",
    "    t_X.loc[s, f'{sensor}_classic_sta_lta1_mean'] = __classic_sta_lta(x, 500, 10000).mean()\n",
    "    t_X.loc[s, f'{sensor}_classic_sta_lta2_mean'] = __classic_sta_lta(x, 5000, 100000).mean()\n",
    "    t_X.loc[s, f'{sensor}_classic_sta_lta3_mean'] = __classic_sta_lta(x, 3333, 6666).mean()\n",
    "    t_X.loc[s, f'{sensor}_classic_sta_lta4_mean'] = __classic_sta_lta(x, 10000, 25000).mean()\n",
    "    return t_X\n",
    "\n",
    "#Fast-Fourier transforms\n",
    "def fft(t_X, x, s, sensor, postfix=''):\n",
    "    \"\"\"Generates basic statistics over the fft of the signal\"\"\"\n",
    "    z = np.fft.fft(x)\n",
    "    fft_real = np.real(z)\n",
    "    fft_imag = np.imag(z)\n",
    "\n",
    "    t_X.loc[s, f'fft_A0']             = abs(z[0])\n",
    "    \n",
    "    t_X.loc[s, f'{sensor}_fft_real_mean{postfix}']      = fft_real.mean()\n",
    "    t_X.loc[s, f'{sensor}_fft_real_std{postfix}']       = fft_real.std()\n",
    "    t_X.loc[s, f'{sensor}_fft_real_max{postfix}']       = fft_real.max()\n",
    "    t_X.loc[s, f'{sensor}_fft_real_min{postfix}']       = fft_real.min()\n",
    "    t_X.loc[s, f'{sensor}_fft_real_median{postfix}']    = np.median(fft_real)\n",
    "    t_X.loc[s, f'{sensor}_fft_real_skew{postfix}']      = spstats.skew(fft_real)\n",
    "    t_X.loc[s, f'{sensor}_fft_real_kurtosis{postfix}']  = spstats.kurtosis(fft_real)\n",
    "    \n",
    "    t_X.loc[s, f'{sensor}_fft_imag_mean{postfix}']      = fft_imag.mean()\n",
    "    t_X.loc[s, f'{sensor}_fft_imag_std{postfix}']       = fft_imag.std()\n",
    "    t_X.loc[s, f'{sensor}_fft_imag_max{postfix}']       = fft_imag.max()\n",
    "    t_X.loc[s, f'{sensor}_fft_imag_min{postfix}']       = fft_imag.min()\n",
    "    t_X.loc[s, f'{sensor}_fft_imag_median{postfix}']    = np.median(fft_imag)\n",
    "    t_X.loc[s, f'{sensor}_fft_imag_skew{postfix}']      = spstats.skew(fft_imag)\n",
    "    t_X.loc[s, f'{sensor}_fft_imag_kurtosis{postfix}']  = spstats.kurtosis(fft_imag)\n",
    "    \n",
    "    return t_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Feature Extraction for training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Datasets/predict-volcanic-eruptions-ingv-oe/train.csv') #path for the train.csv\n",
    "train_set = pd.DataFrame()\n",
    "train_set['segment_id'] = train.segment_id\n",
    "train_set = train_set.set_index('segment_id')\n",
    "\n",
    "j = 0\n",
    "for seg in train.segment_id:\n",
    "    signals = pd.read_csv(f'C:/Datasets/predict-volcanic-eruptions-ingv-oe/train/{seg}.csv')\n",
    "    for i in range(1, 11):\n",
    "        sensor_id = f'sensor_{i}'\n",
    "        train_set = basic_statistics(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        train_set = quantiles(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        train_set = linear_regression(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        train_set = fft(train_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        \n",
    "train_set = pd.merge(train_set.reset_index(), train, on=['segment_id'], how='left').set_index('segment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4431, 442)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_set['time_to_eruption']\n",
    "X_train = train_set.drop(['time_to_eruption'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (4431, 441)\n",
      "y_train :  (4431,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train : ', X_train.shape)\n",
    "print('y_train : ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X_train_T1.pickle\",\"wb\")\n",
    "pickle.dump(X_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_train_T1.pickle\",\"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing and Feature Extraction for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Datasets/predict-volcanic-eruptions-ingv-oe/sample_submission.csv') #path for train.csv\n",
    "test_set = pd.DataFrame()\n",
    "test_set['segment_id'] = test.segment_id\n",
    "test_set = test_set.set_index('segment_id')\n",
    "\n",
    "\n",
    "for seg in test.segment_id:\n",
    "    signals = pd.read_csv(f'C:/Datasets/predict-volcanic-eruptions-ingv-oe/test/{seg}.csv')\n",
    "    for i in range(1, 11):\n",
    "        sensor_id = f'sensor_{i}'\n",
    "        test_set = basic_statistics(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        test_set = quantiles(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        test_set = linear_regression(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')\n",
    "        test_set = fft(test_set, signals[sensor_id].fillna(0), seg, sensor_id, postfix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4520, 441)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = test_set['time_to_eruption']\n",
    "X_test=test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test :  (4520, 441)\n"
     ]
    }
   ],
   "source": [
    "print('X_test : ', X_test.shape)\n",
    "#print('y_test : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X_test_T1.pickle\",\"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
